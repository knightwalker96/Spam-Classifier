{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = pd.read_csv(\"SMSSpamCollection\" , sep = '\\t' , names = ['label' , 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>spam</td>\n",
       "      <td>PRIVATE! Your 2004 Account Statement for 07742...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5343</th>\n",
       "      <td>ham</td>\n",
       "      <td>No go. No openings for that room 'til after th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>spam</td>\n",
       "      <td>GENT! We are trying to contact you. Last weeke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3849</th>\n",
       "      <td>ham</td>\n",
       "      <td>Can you plz tell me the ans. BSLVYL sent via f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3317</th>\n",
       "      <td>ham</td>\n",
       "      <td>I know girls always safe and selfish know i go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277</th>\n",
       "      <td>ham</td>\n",
       "      <td>Best msg: It's hard to be with a person, when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>spam</td>\n",
       "      <td>Monthly password for wap. mobsi.com is 391784....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3753</th>\n",
       "      <td>ham</td>\n",
       "      <td>Why are u up so early?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5507</th>\n",
       "      <td>ham</td>\n",
       "      <td>I want to be inside you every night...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>ham</td>\n",
       "      <td>Why you Dint come with us.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "2095  spam  PRIVATE! Your 2004 Account Statement for 07742...\n",
       "5343   ham  No go. No openings for that room 'til after th...\n",
       "564   spam  GENT! We are trying to contact you. Last weeke...\n",
       "3849   ham  Can you plz tell me the ans. BSLVYL sent via f...\n",
       "3317   ham  I know girls always safe and selfish know i go...\n",
       "5277   ham  Best msg: It's hard to be with a person, when ...\n",
       "1674  spam  Monthly password for wap. mobsi.com is 391784....\n",
       "3753   ham                             Why are u up so early?\n",
       "5507   ham             I want to be inside you every night...\n",
       "265    ham                         Why you Dint come with us."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[['label','message']].sample(10,random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "corpus1 = []\n",
    "corpus2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing the task of preprocessing. Using regular expression to replace any other character except a-z and A-Z\n",
    "#with a blank space.Then canging them into lowercase. After that applying the process of Stemming on each word\n",
    "#to decompose them into their base form. Then the words are appended to the empty list, corpus.\n",
    "\n",
    "for i in range(0,len(messages)):\n",
    "    review = re.sub(\"[^a-zA-Z]\" , \" \" , messages['message'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [ps.stem(word) for word in review if word not in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus1.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(messages)):\n",
    "    review = re.sub(\"[^a-zA-Z]\" , \" \" , messages['message'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [lemmatizer.lemmatize(word) for word in review if word not in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus2.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Bag of Words (BOW) model using Count Vecotrizer\n",
    "#X1 is fitting the BOW model into the Stemmed corpus.\n",
    "#X2 is fitting the BOW model into the Lemmatized corpus.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 5000)\n",
    "X1 = cv.fit_transform(corpus1).toarray()\n",
    "X2 = cv.fit_transform(corpus2).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Term Frequency-Inverse Document Frequeuncy (TF-IDF) model\n",
    "#X1 is fitting the Tf-Idf model into the Stemmed corpus.\n",
    "#X2 is fitting the Tf-Idf model into the Lemmatized corpus.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features = 5000)\n",
    "X3 = tfidf.fit_transform(corpus1).toarray()\n",
    "X4 = tfidf.fit_transform(corpus2).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ham  spam\n",
       "0       1     0\n",
       "1       1     0\n",
       "2       0     1\n",
       "3       1     0\n",
       "4       1     0\n",
       "...   ...   ...\n",
       "5567    0     1\n",
       "5568    1     0\n",
       "5569    1     0\n",
       "5570    1     0\n",
       "5571    1     0\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(messages['label'])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classifying the spam messages to be 1 and the non-spam messages to be 0.\n",
    "y = y.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X1_train,X1_test,y1_train,y1_test = train_test_split(X1,y,test_size=0.25,random_state = 42)\n",
    "X2_train,X2_test,y2_train,y2_test = train_test_split(X2,y,test_size=0.25,random_state = 42)\n",
    "X3_train,X3_test,y3_train,y3_test = train_test_split(X3,y,test_size=0.25,random_state = 42)\n",
    "X4_train,X4_test,y4_train,y4_test = train_test_split(X4,y,test_size=0.25,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "spam_model1 = MultinomialNB().fit(X1_train,y1_train)\n",
    "spam_model2 = MultinomialNB().fit(X2_train,y2_train)\n",
    "spam_model3 = MultinomialNB().fit(X3_train,y3_train)\n",
    "spam_model4 = MultinomialNB().fit(X4_train,y4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = spam_model1.predict(X1_test)\n",
    "y_pred2 = spam_model2.predict(X2_test)\n",
    "y_pred3 = spam_model3.predict(X3_test)\n",
    "y_pred4 = spam_model4.predict(X4_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1191,   16],\n",
       "       [  10,  176]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm1 = confusion_matrix(y1_test , y_pred1)\n",
    "cm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1188,   19],\n",
       "       [  10,  176]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm2 = confusion_matrix(y2_test , y_pred2)\n",
    "cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1206,    1],\n",
       "       [  41,  145]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm3 = confusion_matrix(y3_test , y_pred3)\n",
    "cm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1206,    1],\n",
       "       [  38,  148]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm4 = confusion_matrix(y4_test , y_pred4)\n",
    "cm4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.1335247666906"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy1 = accuracy_score(y1_test , y_pred1)\n",
    "accuracy1*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.91816223977028"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy2 = accuracy_score(y2_test , y_pred2)\n",
    "accuracy2*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.98492462311557"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy3 = accuracy_score(y3_test , y_pred3)\n",
    "accuracy3*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.20028715003589"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy4 = accuracy_score(y4_test , y_pred4)\n",
    "accuracy4*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Model Used': ['BOW' , 'BOW' , 'TfIdf' , 'TfIdf'] , \n",
    "                   'Type of Text Normalization used': ['Stemming' , 'Lemmatization' , 'Stemming' , 'Lemmatization'] , \n",
    "                   'Accuracy': [accuracy1*100 , accuracy2*100 , accuracy3*100 , accuracy4*100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Used</th>\n",
       "      <th>Type of Text Normalization used</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOW</td>\n",
       "      <td>Stemming</td>\n",
       "      <td>98.133525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOW</td>\n",
       "      <td>Lemmatization</td>\n",
       "      <td>97.918162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TfIdf</td>\n",
       "      <td>Stemming</td>\n",
       "      <td>96.984925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TfIdf</td>\n",
       "      <td>Lemmatization</td>\n",
       "      <td>97.200287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Used Type of Text Normalization used   Accuracy\n",
       "0        BOW                        Stemming  98.133525\n",
       "1        BOW                   Lemmatization  97.918162\n",
       "2      TfIdf                        Stemming  96.984925\n",
       "3      TfIdf                   Lemmatization  97.200287"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can conclude from the above table that the first model, ie BOW+Stemming performs the best\n",
    "#among all the four models with an accuracy score of 98.13%. The TfIdf+Stemming model performs\n",
    "#the worst with an accuracy score of 96.98%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
